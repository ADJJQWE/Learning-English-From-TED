# Is Xi Jinping an AI doomer?

China’s elite is split over artificial intelligence

![image-20240830154724263](./assets/image-20240830154724263.png)

原文：

IN JULY last year Henry Kissinger travelled to Beijing for the final time

before his death. Among the messages he delivered to China’s ruler, Xi

Jinping, was a warning about the catastrophic risks of artificial intelligence

(AI). Since then American tech bosses and ex-government officials have

quietly met their Chinese counterparts in a series of informal gatherings

dubbed the Kissinger Dialogues. The conversations have focused in part on

how to protect the world from the dangers of AI. American and Chinese

officials are thought to have also discussed the subject (along with many

others) when America’s national security adviser, Jake Sullivan, visited

Beijing from August 27th to 29th.

去年7月，亨利·基辛格在去世前最后一次前往北京。在他向中国统治者传递的信息中，有一条是关于人工智能(AI)灾难性风险的警告。从那以后，美国的科技老板和前政府官员在一系列被称为基辛格对话的非正式聚会中悄悄地会见了他们的中国同行。对话部分集中在如何保护世界免受人工智能的威胁。当美国国家安全顾问杰克·沙利文于8月27日至29日访问北京时，美国和中国官员被认为也讨论了这个问题(以及其他许多问题)。

学习：

dub：美 [dʌb]  给…起绰号；把…戏称为；授予称号；

原文：

Many in the tech world think that AI will come to match or surpass the

cognitive abilities of humans. Some developers predict that artificial general

intelligence (AGI) models will one day be able to learn unaided, which could

make them uncontrollable. Those who believe that, left unchecked, AI poses

an existential risk to humanity are called “doomers”. They tend to advocate

stricter regulations. On the other side are “accelerationists”, who stress AI’s

potential to benefit humanity.

科技界的许多人认为，人工智能将达到或超过人类的认知能力。一些开发人员预测，通用人工智能(AGI)模型有一天将能够独立学习，这可能会使他们无法控制。那些认为如果不加以控制，人工智能会给人类带来生存风险的人被称为“末日论者”。他们倾向于主张更严格的法规。另一边是“加速论者”，他们强调人工智能造福人类的潜力。

学习：

unaided：无帮助的；独立的；无辅助的

existential risk：生存风险

doomer：末日论者

原文：

Western accelerationists often argue that competition with Chinese

developers, who are uninhibited by strong safeguards, is so fierce that the

West cannot afford to slow down. The implication is that the debate in China

is one-sided, with accelerationists having the most say over the regulatory

environment. In fact, China has its own AI doomers—and they are

increasingly influential.

西方加速主义者经常认为，与中国开发者的竞争如此激烈，以至于西方承受不起放缓的代价。中国开发商没有受到强有力的保护措施的约束。这意味着中国的辩论是一边倒的，加速论者对监管环境最有发言权。事实上，中国有自己的人工智能末日论者——而且它们的影响力越来越大。

学习：

uninhibited：无拘无束的；随心所欲的；不受限制的

safeguards：保护措施；保卫；安全设施；（safeguard的复数）

implication：意味着，影响

原文：

Until recently China’s regulators have focused on the risk of rogue chatbots

saying politically incorrect things about the Communist Party, rather than

that of cutting-edge models slipping out of human control. In 2023 the

government required developers to register their large language models.

Algorithms are regularly marked on how well they comply with socialist

values and whether they might “subvert state power”. The rules are also

meant to prevent discrimination and leaks of customer data. But, in general,

AI-safety regulations are light. Some of China’s more onerous restrictions

were rescinded last year.

直到最近，中国监管机构一直关注不守规矩的聊天机器人对共产党发表政治不正确言论的风险，而不是尖端模型脱离人类控制的风险。2023年，政府要求开发者注册他们的大型语言模型。算法通常被标记为符合社会主义价值观的程度，以及它们是否可能“颠覆国家政权”。这些规定也是为了防止歧视和泄露客户数据。但是，总的来说，人工智能安全条例是宽松的。去年，中国取消了一些较为苛刻的限制。

学习：

rouge：无赖；流氓；恶棍；骗子；淘气鬼；调皮鬼；捣蛋鬼；行为异常者；不守规矩的人

politically incorrect：政治不正确的

slip out of：脱离

slip out of human control：脱离人类控制

comply with：遵守，符合

subvert：颠覆；推翻；破坏

regulations are light：监管是宽松的

onerous restrictions：苛刻的限制

rescinded：美 [rɪˈsɪndid] 废除；（rescind的过去式和过去分词）

原文：

China’s accelerationists want to keep things this way. Zhu Songchun, a party

adviser and director of a state-backed programme to develop AGI, has argued

that AI development is as important as the “Two Bombs, One Satellite”

project, a Mao-era push to produce long-range nuclear weapons. Earlier this

year Yin Hejun, the minister of science and technology, used an old party

slogan to press for faster progress, writing that development, including in the

field of AI, was China’s greatest source of security. Some economic

policymakers warn that an over-zealous pursuit of safety will harm China’s

competitiveness.

中国的加速主义者希望保持现状。中共中央政治局委员、国家支持的发展项目负责人Zhu认为，人工智能的发展与“两弹一星”计划同等重要。两弹一星是毛时代推动中国制造远程核武器的项目。今年早些时候，科技部部长Yin用一个老的党口号来敦促更快的发展，他写道，发展，包括在人工智能领域的发展，是中国最大的安全来源。一些经济政策制定者警告说，过度追求安全将损害中国的竞争力。

学习：

Two Bombs, One Satellite：两弹一星

over-zealous：热心过度的；过于狂热的；过分热心的          

原文：

But the accelerationists are getting pushback from a clique of elite scientists

with the party’s ear. Most prominent among them is Andrew Chi-Chih Yao,

the only Chinese person to have won the Turing award for advances in

computer science. In July Mr Yao said AI posed a greater existential risk to

humans than nuclear or biological weapons. Zhang Ya-Qin, the former

president of Baidu, a Chinese tech giant, and Xue Lan, the chairman of the

state’s expert committee on AI governance, also reckon that AI may threaten

the human race. Yi Zeng of the Chinese Academy of Sciences believes that

AGI models will eventually see humans as humans see ants.

但是加速论者正受到党内精英科学家小集团的抵制。其中最突出的是安德鲁·姚期智，他是唯一一位因在计算机科学方面的进步而获得图灵奖的中国人。今年7月，姚表示，与核武器或生物武器相比，人工智能对人类构成了更大的生存风险。中国科技巨头百度前总裁张亚勤和国家人工智能治理专家委员会主席 Xue Lan也认为人工智能可能会威胁到人类。中国科学院的Yi Zeng认为，AGI模型最终会像人类看待蚂蚁一样看待人类。

学习：

pushback：（对政策、规范等的）抗拒、反对；

clique：英 [kliːk] 小集团；小圈子；派系

原文：

The influence of such arguments is increasingly on display. In March an

international panel of experts meeting in Beijing called on researchers to kill

models that appear to seek power or show signs of self-replication or deceit.

A short time later the risks posed by AI, and how to control them, became a

subject of study sessions for party leaders. A state body that funds scientific

research has begun offering grants to researchers who study how to align AI

with human values. State labs are doing increasingly advanced work in this

domain. Private firms have been less active, but more of them have at least

begun paying lip service to the risks of AI.

这些争论的影响越来越明显。今年3月，一个国际专家小组在北京召开会议，呼吁研究人员杀死那些似乎寻求权力或表现出自我复制或欺骗迹象的模型。不久之后，人工智能带来的风险，以及如何控制这些风险，成为党的领导人学习会议的主题。一个资助科学研究的国家机构已经开始向研究如何将人工智能与人类价值观相结合的研究人员提供资助。国家实验室在这一领域的工作越来越先进。私人公司不太积极，但他们中的大多数至少已经开始口头上承认人工智能的风险。

学习：

grants：拨款

lip service：嘴皮子；表面文章          

## **Speed up or slow down?**

原文：

The debate over how to approach the technology has led to a turf war

between China’s regulators. The industry ministry has called attention to

safety concerns, telling researchers to test models for threats to humans. But

it seems that most of China’s securocrats see falling behind America as a

bigger risk. The science ministry and state economic planners also favour

faster development. A national AI law slated for this year fell off the

government’s work agenda in recent months because of these disagreements.

The impasse was made plain on July 11th, when the official responsible for

writing the AI law cautioned against prioritising either safety or expediency.

关于如何对待这项技术的争论导致了中国监管机构之间的地盘之争。工业部呼吁关注安全问题，告诉研究人员测试模型对人类的威胁。但似乎大多数中国官员认为落后于美国是一个更大的风险。科技部和国家经济规划者也支持更快的发展。由于这些分歧，最近几个月，一项定于今年实施的国家人工智能法从政府的工作议程上落了下来。7月11日，当负责起草人工智能法律的官员警告不要优先考虑安全或权宜之计时，僵局变得明显。

学习：

turf：草皮；草坪；（铺草坪用的）草皮块

turf war：地盘争夺战；势力争夺战；地盘之争；势力范围之争；

securocrat：英 [sɪˈkjʊərə(ʊ)krat]  安全官员；安全事务专家；安全政策制定者；安全顾问

slate：计划；安排

impasse：美 [ˈɪmˌpæs] 僵局；死胡同；绝境；难题

caution：警告；发出正式警告；告诫；

expediency：美 [ɪkˈspiːdiənsi] 方便；私利；权宜

原文：

The decision will ultimately come down to what Mr Xi thinks. In June he

sent a letter to Mr Yao, praising his work on AI. In July, at a meeting of the

party’s Central Committee called the “third plenum”, Mr Xi sent his clearest

signal yet that he takes the doomers’ concerns seriously. The official report

from the plenum listed AI risks alongside other big concerns, such as

biohazards and natural disasters. For the first time it called for monitoring AI

safety, a reference to the technology’s potential to endanger humans. The

report may lead to new restrictions on AI-research activities.

这个决定最终将取决于主席先生的想法。6月，他给姚先生写了一封信，赞扬了他在人工智能方面的工作。今年7月，在一次名为“三中全会”的中共中央委员会会议上，主席发出了迄今为止最明确的信号，表示他认真对待末日论者的担忧。全会的官方报告列出了人工智能风险以及其他重大问题，如生物危害和自然灾害。它首次呼吁监控人工智能的安全，这是指该技术可能危及人类。该报告可能会导致对人工智能研究活动的新限制。

学习：

come down to：（问题、决定等）归结为；取决于

原文：

More clues to Mr Xi’s thinking come from the study guide prepared for

party cadres, which he is said to have personally edited. China should

“abandon uninhibited growth that comes at the cost of sacrificing safety”,

says the guide. Since AI will determine “the fate of all mankind”, it must

always be controllable, it goes on. The document calls for regulation to be

pre-emptive rather than reactive.

主席先生思想的更多线索来自为党的干部准备的学习指南，据说是他亲自编辑的。该指南称，中国应该“放弃以牺牲安全为代价的无节制增长”。既然人工智能将决定“全人类的命运”，它就必须永远是可控的。这份文件呼吁监管要先发制人，而不是被动反应。

学习：

study guide：学习指南

cadres：美 [ˈkædri:z] 骨干；干部；骨骼；（cadre的复数）

pre-emptive：先发制人的；预防性的；

reactive：被动的

原文：

Safety gurus say that what matters is how these instructions are

implemented. China will probably create an AI-safety institute to observe

cutting-edge research, as America and Britain have done, says Matt Sheehan

of the Carnegie Endowment for International Peace, a think-tank in

Washington. Which department would oversee such an institute is an open

question. For now Chinese officials are emphasising the need to share the

responsibility of regulating AI and to improve co-ordination.

安全专家说，重要的是如何执行这些指令。华盛顿智库卡内基国际和平基金会的马特·希恩说，中国可能会像美国和英国一样，建立一个人工智能安全研究所来观察前沿研究。哪个部门将监管这样一个机构是一个悬而未决的问题。目前，中国官员强调需要分担监管人工智能的责任，并加强协调。

学习：

gurus：权威；（guru的复数）

open question：悬而未决的问题；未解决的问题；

原文：

If China does move ahead with efforts to restrict the most advanced AI

research and development, it will have gone further than any other big

country. Mr Xi says he wants to “strengthen the governance of artificial

intelligence rules within the framework of the United Nations”. To do that

China will have to work more closely with others. But America and its

friends are still considering the issue. The debate between doomers and

accelerationists, in China and elsewhere, is far from over. ■

如果中国真的继续努力限制最先进的人工智能研发，它将比任何其他大国走得更远。主席表示，他希望“在联合国框架内加强人工智能规则的治理”。要做到这一点，中国必须与其他国家更紧密地合作。但是美国及其盟友仍在考虑这个问题。在中国和其他地方，末日论者和加速论者之间的争论远未结束。■



## 后记

2024年8月30日16点15分于上海。

